#!/usr/bin/env python3

import argparse
import subprocess
from pathlib import Path
from Bio import SeqIO
import pandas as pd

def resolve_genes_to_longest_transcripts(ref_gtf, gene_ids):
    """
    Map each gene_id to its longest transcript_id using the reference GTF.
    Length is computed as transcript/mRNA span (end - start + 1).
    Returns a list of transcript_ids in the same order as the input gene_ids (deduped).
    """
    print("üìù Resolving gene IDs to longest transcript IDs from reference GTF...")

    # Ensure GTF (convert GFF->GTF if needed)
    gtf_path = Path(ref_gtf)
    if gtf_path.suffix != ".gtf":
        print("üß¨ Converting reference GFF to GTF via gffread...")
        converted = gtf_path.with_suffix(".gtf")
        subprocess.run(["gffread", str(gtf_path), "-T", "-o", str(converted)], check=True)
        ref_gtf = str(converted)

    # Load GTF
    cols = ['seqid','source','type','start','end','score','strand','phase','attributes']
    gtf = pd.read_csv(ref_gtf, sep="\t", comment="#", header=None, names=cols)

    # Keep transcript-like rows
    tx = gtf[gtf['type'].isin(['transcript','mRNA'])].copy()

    # Extract IDs (return Series via expand=False)
    tx['transcript_id'] = tx['attributes'].str.extract(r'transcript_id "?([^";]+)"?', expand=False)
    tx['gene_id_attr']  = tx['attributes'].str.extract(r'gene_name "?([^";]+)"?', expand=False)

    # Fallbacks for gene id (some refs store gene= or gene_name= in attributes)
    tx['gene_id_attr'] = tx['gene_id_attr'].fillna(
        tx['attributes'].str.extract(r'gene=([^;]+)', expand=False)
    )
    tx['gene_id_attr'] = tx['gene_id_attr'].fillna(
        tx['attributes'].str.extract(r'gene_name "?([^";]+)"?', expand=False)
    )

    # Compute transcript span length
    tx['tx_len'] = (tx['end'] - tx['start'] + 1).astype('Int64')

    # Pick the longest transcript per gene
    longest_tx = (
        tx.dropna(subset=['transcript_id','gene_id_attr'])
          .sort_values(['gene_id_attr', 'tx_len'], ascending=[True, False])
          .groupby('gene_id_attr', as_index=False)
          .first()[['gene_id_attr','transcript_id','tx_len']]
    )

    # Build mapping gene_id -> transcript_id
    g2t = dict(zip(longest_tx['gene_id_attr'], longest_tx['transcript_id']))

    # Resolve the provided gene_ids in the original order
    resolved, missing = [], []
    for gid in gene_ids:
        if gid in g2t:
            resolved.append(g2t[gid])
        else:
            # light prefix fallback (e.g., some GTFs have "gene-<id>")
            alt = f"gene-{gid}"
            if alt in g2t:
                resolved.append(g2t[alt])
            else:
                missing.append(gid)

    print(f"‚úÖ Resolved {len(resolved)} gene IDs to longest transcripts.")
    if missing:
        preview = ", ".join(missing[:5])
        more = " ..." if len(missing) > 5 else ""
        print(f"‚ö†Ô∏è {len(missing)} gene IDs not found in reference GTF: {preview}{more}")

    # Deduplicate while preserving order
    seen, resolved_unique = set(), []
    for tid in resolved:
        if tid not in seen:
            seen.add(tid)
            resolved_unique.append(tid)

    return resolved_unique


def run_gffread(genome_fasta, gtf_file, output_protein_fasta):
    print(f"\n\U0001f9ec Running gffread to extract proteins from {gtf_file}\n")
    cmd = [
        "gffread", gtf_file,
        "-g", genome_fasta,
        "-y", output_protein_fasta
    ]
    subprocess.run(cmd, check=True)
    print(f"\n\u2705 Protein FASTA saved to {output_protein_fasta}\n")

def extract_proteins(input_fasta, id_list, output_fasta):
    print(f"üîç Checking for duplicate transcript IDs in {input_fasta}")
    seen = {}
    dedup_records = []
    duplicate_count = 0

    for record in SeqIO.parse(input_fasta, "fasta"):
        if record.id in seen:
            duplicate_count += 1
            seen[record.id] += 1
            new_id = f"{record.id}_dup{seen[record.id]}"
            print(f"  ‚Ä¢ Duplicate found: {record.id} ‚ûù renamed to {new_id}")
            record.id = new_id
            record.description = new_id
        else:
            seen[record.id] = 0
        dedup_records.append(record)

    if duplicate_count > 0:
        print(f"‚ö†Ô∏è Found {duplicate_count} duplicate transcript IDs. Renamed with _dup1, _dup2, etc.")

    # Convert deduplicated list to a lookup dict
    records_dict = {rec.id: rec for rec in dedup_records}

    # Match by prefix to include any renamed duplicates
    with open(output_fasta, "w") as out_f:
        for pid in id_list:
            matches = [rid for rid in records_dict if rid.startswith(pid)]
            if matches:
                for rid in matches:
                    SeqIO.write(records_dict[rid], out_f, "fasta")
            else:
                print(f"‚ö†Ô∏è WARNING: Protein ID '{pid}' not found in {input_fasta}")

    print(f"‚úÖ Extracted protein sequences saved to {output_fasta}")

def make_blast_db(fasta, dbtype="prot", log_dir=None):
    print(f"\n\U0001f527 Creating BLAST database for {fasta}\n")
    cmd = [
        "makeblastdb",
        "-in", fasta,
        "-dbtype", dbtype
    ]
    if log_dir:
        log_file = Path(log_dir) / f"makeblastdb_{Path(fasta).stem}.log"
        with open(log_file, "w") as lf:
            subprocess.run(cmd, check=True, stdout=lf, stderr=lf)
    else:
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    print(f"\n\u2705 BLAST database created for {fasta}\n")

def run_blastp(query_fasta, db_fasta, output_file, log_dir=None):
    print(f"\n\U0001f50d Running blastp: {query_fasta} vs {db_fasta}\n")
    cmd = [
        "blastp",
        "-query", str(query_fasta),
        "-db", str(db_fasta),
        "-out", str(output_file),
        "-evalue", "1e-5",
        "-outfmt", "6",
        "-max_target_seqs", "1",
        "-num_threads", "4"
    ]
    log_file = Path(log_dir) / f"blastp_{Path(query_fasta).stem}_vs_{Path(db_fasta).stem}.log"
    with open(log_file, "w") as lf:
        subprocess.run(cmd, check=True, stdout=lf, stderr=lf)
    print(f"\n\u2705 blastp completed. Output: {output_file}\n")

def find_flanking_genes(gtf_file, target_id, method, window, verbose=True):
    gtf = pd.read_csv(gtf_file, sep='\t', comment='#', header=None,
                      names=['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes'])
    genes = gtf[gtf['type'].isin(['transcript', 'mRNA'])].copy()
    genes['gene_id'] = genes['attributes'].str.extract('transcript_id "([^"]+)"')
    genes = genes.dropna(subset=['gene_id']).reset_index(drop=True)
    genes = genes.sort_values(by=['seqid', 'start']).reset_index(drop=True)

    if target_id not in genes['gene_id'].values:
        print(f"\n\u26a0\ufe0f Target ID '{target_id}' not found in GTF.\n")
        return []

    idx = genes[genes['gene_id'] == target_id].index[0]

    if method == 'gene':
        upstream = genes.iloc[max(0, idx-window):idx]
        downstream = genes.iloc[idx+1:idx+1+window]
    elif method == 'bp':
        chrom = genes.loc[idx, 'seqid']
        start = genes.loc[idx, 'start']
        end = genes.loc[idx, 'end']
        upstream = genes[(genes['seqid'] == chrom) & (genes['end'] < start) & (genes['end'] >= start - window)]
        downstream = genes[(genes['seqid'] == chrom) & (genes['start'] > end) & (genes['start'] <= end + window)]
    else:
        raise ValueError("Method must be 'gene' or 'bp'")

    flank_ids = list(upstream['gene_id']) + [target_id] + list(downstream['gene_id'])

    if verbose:
        print(f"\n\U0001f4cb Found {len(upstream)} upstream and {len(downstream)} downstream transcripts.\n")

    return flank_ids

def parse_args():
    parser = argparse.ArgumentParser(description="Step 1: Extract proteins from genome and build BLAST DB")

    parser.add_argument("-r", "--ref_genome", required=True, help="Reference genome FASTA file")
    parser.add_argument("-g", "--ref_gtf", required=True, help="Reference genome GTF file")
    parser.add_argument("-i", "--ref_ids", required=True, help="Comma-separated list of reference protein/gene IDs to extract")
    parser.add_argument("-y", "--id_type", choices=["transcript", "gene"], default="transcript", help="Type of IDs provided to --ref_ids (default: transcript). If 'gene', the longest transcript per gene will be used.")
    parser.add_argument("-q", "--query_genome", required=True, help="Query genome FASTA file")
    parser.add_argument("-t", "--query_gtf", required=True, help="Query GTF file")
    parser.add_argument("-o", "--outdir", required=True, help="Directory to save all outputs")
    parser.add_argument("-m", "--flank_method", choices=["gene", "bp"], default="gene", help="Flanking extraction method: 'gene' or 'bp' distance")
    parser.add_argument("-w", "--window", type=int, default=5, help="Window size for flanking region (n genes or base pairs)")
    parser.add_argument("--export_gff3_regions", action="store_true", help="Export reference and query regions as GFF3 with embedded FASTA for Geneious")

    return parser.parse_args()


def summarize_query_hits(blast_file, query_gtf):
    # Convert GFF to GTF if needed
    gtf_path = Path(query_gtf)
    if not gtf_path.suffix == ".gtf":
        print(f"\n\U0001f9ec Converting query GFF to GTF format using gffread...")
        converted_gtf = gtf_path.with_suffix(".gtf")
        subprocess.run([
            "gffread", str(gtf_path),
            "-T", "-o", str(converted_gtf)
        ], check=True)
        query_gtf = str(converted_gtf)
        print(f"\n‚úÖ Converted to GTF: {query_gtf}\n")
    print("üîé Checking chromosome congruence of query BLAST hits...")

    # Load BLAST results
    cols = ["qseqid", "sseqid", "pident", "length", "mismatch", "gapopen",
            "qstart", "qend", "sstart", "send", "evalue", "bitscore"]
    blast_df = pd.read_csv(blast_file, sep="\t", header=None, names=cols)

    # Load query GTF to get chromosome locations
    gtf = pd.read_csv(query_gtf, sep='\t', comment='#', header=None,
                      names=['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes'])
    genes = gtf[gtf['type'] == 'transcript'].copy()
    genes['gene_id'] = genes['attributes'].str.extract('transcript_id "([^";]+)"')

    # Map sseqid from BLAST to seqid in GTF
    merged = blast_df.merge(genes[['gene_id', 'seqid', 'start']], left_on='sseqid', right_on='gene_id', how='left')

    print("\nüß¨ Query BLAST Hits Chromosome Summary:\n")
    chrom_counts = merged['seqid'].value_counts()
    print(chrom_counts.to_string())

    # Print ordered list
    print("\nüß≠ Order of hits on top query contig:\n")
    top_chrom = chrom_counts.idxmax()
    ordered = merged[merged['seqid'] == top_chrom].sort_values(by='start')
    for _, row in ordered.iterrows():
        print(f"{row['qseqid']} ‚ûù {row['sseqid']} on {row['seqid']} @ {row['start']}")

def generate_gggenomes_tracks(blast_file, query_gtf, output_dir, ref_gtf):
    print("üìà Generating gggenomes tracks...")

    # Load BLAST results
    cols = ["qseqid", "sseqid", "pident", "length", "mismatch", "gapopen",
            "qstart", "qend", "sstart", "send", "evalue", "bitscore"]
    blast_df = pd.read_csv(blast_file, sep="\t", header=None, names=cols)

    # --- Handle QUERY GTF ---
    query_gtf_path = Path(query_gtf)
    if not query_gtf_path.suffix == ".gtf":
        print("üß¨ Converting query GFF to GTF format using gffread...")
        converted_gtf = query_gtf_path.with_suffix(".gtf")
        subprocess.run([
            "gffread", str(query_gtf_path), "-T", "-o", str(converted_gtf)
        ], check=True)
        query_gtf = str(converted_gtf)

    query_df = pd.read_csv(query_gtf, sep="\t", comment="#", header=None,
                           names=['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes'])
    query_tx = query_df[query_df['type'].isin(['transcript', 'mRNA'])].copy()
    query_tx['transcript_id'] = query_tx['attributes'].str.extract('transcript_id "?([^";]+)"?')
    query_tx['gene_name'] = query_tx['attributes'].str.extract('gene_name "?([^";]+)"?')
    query_tx = query_tx[['transcript_id', 'gene_name', 'seqid', 'start', 'end']].dropna()

    # --- Handle REF GTF ---
    ref_df = pd.read_csv(ref_gtf, sep="\t", comment="#", header=None,
                         names=['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes'])
    ref_tx = ref_df[ref_df['type'].isin(['transcript', 'mRNA'])].copy()
    ref_tx['transcript_id'] = ref_tx['attributes'].str.extract('transcript_id "?([^";]+)"?')
    ref_tx['gene_name'] = ref_tx['attributes'].str.extract('gene_name "?([^";]+)"?')
    ref_tx = ref_tx[['transcript_id', 'gene_name', 'seqid', 'start', 'end']].dropna()

    # --- Merge BLAST hits with coords ---
    merged = blast_df.merge(ref_tx, left_on='qseqid', right_on='transcript_id', how='left')\
                     .merge(query_tx, left_on='sseqid', right_on='transcript_id', how='left',
                            suffixes=('_ref', '_qry'))

    # --- Coordinate resets ---
    min_ref = merged['start_ref'].min()
    min_qry = merged['start_qry'].min()
    shift_ref = min_ref - 3000 if min_ref > 3000 else 0
    shift_qry = min_qry - 3000 if min_qry > 3000 else 0

    merged['ref_start'] = merged['start_ref'] - shift_ref
    merged['ref_end'] = merged['end_ref'] - shift_ref
    merged['qry_start'] = merged['start_qry'] - shift_qry
    merged['qry_end'] = merged['end_qry'] - shift_qry

    # --- SEQ track ---
    seqs_df = pd.concat([
        merged[['seqid_ref', 'ref_end']].rename(columns={'seqid_ref': 'seq_id', 'ref_end': 'length'}),
        merged[['seqid_qry', 'qry_end']].rename(columns={'seqid_qry': 'seq_id', 'qry_end': 'length'})
    ])
    seqs_df = seqs_df.groupby('seq_id')['length'].max().reset_index()
    seqs_df['length'] = seqs_df['length'] + 3000  # buffer
    seqs_df.to_csv(Path(output_dir) / "gggenomes_seqs.tsv", sep='\t', index=False)

    # --- GENE track ---
    genes_df = pd.concat([
        merged[['seqid_ref', 'ref_start', 'ref_end', 'transcript_id_ref', 'gene_name_ref']]
            .rename(columns={
                'seqid_ref': 'seq_id',
                'ref_start': 'start',
                'ref_end': 'end',
                'transcript_id_ref': 'transcript_id',
                'gene_name_ref': 'gene_name'
            }),
        merged[['seqid_qry', 'qry_start', 'qry_end', 'transcript_id_qry', 'gene_name_qry']]
            .rename(columns={
                'seqid_qry': 'seq_id',
                'qry_start': 'start',
                'qry_end': 'end',
                'transcript_id_qry': 'transcript_id',
                'gene_name_qry': 'gene_name'
            })
    ])
    genes_df.to_csv(Path(output_dir) / "gggenomes_genes.tsv", sep='\t', index=False)

    # --- LINKS track ---
    links_df = merged.rename(columns={
        'seqid_ref': 'seq_id',
        'ref_start': 'start',
        'ref_end': 'end',
        'seqid_qry': 'seq_id2',
        'qry_start': 'start2',
        'qry_end': 'end2'
    })[['seq_id', 'start', 'end', 'seq_id2', 'start2', 'end2']]
    links_df.to_csv(Path(output_dir) / "gggenomes_links.tsv", sep='\t', index=False)

    print("‚úÖ gggenomes files written: seqs.tsv, genes.tsv, links.tsv")

def run_gggenomes_plot(seqs_file, genes_file, links_file, output_pdf):
    print("üé® Generating synteny plot with gggenomes...")

    r_script = f"""
    library(tibble)
    library(gggenomes)

    # Load input files
    seqs <- readr::read_tsv("{seqs_file}")
    genes <- readr::read_tsv("{genes_file}")
    links <- readr::read_tsv("{links_file}")

    # Generate plot
    p <- gggenomes(genes=genes, seqs=seqs, links=links) +
        geom_link() +
        geom_seq() +
        geom_seq_label() +
        geom_gene_tag(aes(label=gene_name), nudge_y=0.1, check_overlap = TRUE) +
        geom_gene(aes(fill=gene_name), alpha = 0.3) 

    # Save plot
    ggplot2::ggsave("{output_pdf}", plot=p, width=10, height=4)
    """

    # Write R script to temp file
    tmp_r_path = Path(output_pdf).with_suffix(".plot_gggenomes.R")
    with open(tmp_r_path, "w") as f:
        f.write(r_script)

    # Run R script
    try:
        subprocess.run(["Rscript", str(tmp_r_path)], check=True)
        print(f"‚úÖ Synteny plot saved to: {output_pdf}")
    except subprocess.CalledProcessError:
        print("‚ùå Error while running Rscript for gggenomes plot.")

def export_region_gff3_with_fasta(
    blast_file, ref_gtf, query_gtf, ref_genome_fa, query_genome_fa, outdir, padding=3000
):
    print("üß¨ Exporting regional GFF3 (with embedded FASTA) for Geneious...")

    outdir = Path(outdir)
    regions_dir = outdir / "regions_gff3"
    regions_dir.mkdir(exist_ok=True)

    # --- Load BLAST ---
    cols = ["qseqid","sseqid","pident","length","mismatch","gapopen","qstart","qend","sstart","send","evalue","bitscore"]
    b = pd.read_csv(blast_file, sep="\t", header=None, names=cols)

    # --- Ensure GTF (convert if GFF) ---
    def ensure_gtf(path_str):
        p = Path(path_str)
        if p.suffix != ".gtf":
            print(f"üß™ Converting {p.name} to GTF with gffread...")
            conv = p.with_suffix(".gtf")
            subprocess.run(["gffread", str(p), "-T", "-o", str(conv)], check=True)
            return str(conv)
        return path_str

    ref_gtf = ensure_gtf(ref_gtf)
    query_gtf = ensure_gtf(query_gtf)

    # --- Load annotations ---
    cols_gtf = ['seqid','source','type','start','end','score','strand','phase','attributes']
    ref_df  = pd.read_csv(ref_gtf,   sep="\t", comment="#", header=None, names=cols_gtf)
    qry_df  = pd.read_csv(query_gtf, sep="\t", comment="#", header=None, names=cols_gtf)

    # transcripts table (supports transcript|mRNA)
    def tx_table(df):
        tx = df[df['type'].isin(['transcript','mRNA'])].copy()
        tx['transcript_id'] = tx['attributes'].str.extract(r'transcript_id "?([^";]+)"?')
        tx['gene_id']       = tx['attributes'].str.extract(r'gene_id "?([^";]+)"?')
        return tx[['transcript_id','gene_id','seqid','start','end']].dropna()

    ref_tx = tx_table(ref_df)
    qry_tx = tx_table(qry_df)

    # --- Merge BLAST hits with coords ---
    m = (b.merge(ref_tx, left_on="qseqid", right_on="transcript_id", how="left")
          .merge(qry_tx, left_on="sseqid", right_on="transcript_id", how="left",
                 suffixes=("_ref","_qry")))

    # Pick dominant contig on each side
    def pick_contig(series):
        vc = series.value_counts()
        return vc.index[0] if not vc.empty else None

    ref_contig = pick_contig(m["seqid_ref"])
    qry_contig = pick_contig(m["seqid_qry"])
    if ref_contig is None or qry_contig is None:
        print("‚ö†Ô∏è Could not determine contigs from BLAST+GTF. Aborting GFF3 export.")
        return

    # Region bounds + padding
    ref_start = max(1, int(m.loc[m["seqid_ref"] == ref_contig, "start_ref"].min()) - padding)
    ref_end   = int(m.loc[m["seqid_ref"] == ref_contig, "end_ref"].max()) + padding
    qry_start = max(1, int(m.loc[m["seqid_qry"] == qry_contig, "start_qry"].min()) - padding)
    qry_end   = int(m.loc[m["seqid_qry"] == qry_contig, "end_qry"].max()) + padding

    # Subset features (keep everything useful)
    keep_types = {"gene","mRNA","transcript","exon","CDS","five_prime_UTR","three_prime_UTR","UTR","intron"}
    ref_sub = ref_df[(ref_df['seqid']==ref_contig) &
                     (ref_df['end']>=ref_start) &
                     (ref_df['start']<=ref_end) &
                     (ref_df['type'].isin(keep_types))].copy()
    qry_sub = qry_df[(qry_df['seqid']==qry_contig) &
                     (qry_df['end']>=qry_start) &
                     (qry_df['start']<=qry_end) &
                     (qry_df['type'].isin(keep_types))].copy()

    # Shift coordinates so region starts at 1
    ref_shift = ref_start - 1
    qry_shift = qry_start - 1
    ref_sub["start"] = ref_sub["start"] - ref_shift
    ref_sub["end"]   = ref_sub["end"]   - ref_shift
    qry_sub["start"] = qry_sub["start"] - qry_shift
    qry_sub["end"]   = qry_sub["end"]   - qry_shift

    # Rename seqid to region ID (so FASTA header matches)
    ref_region_id = f"ref_{ref_contig}_{ref_start}-{ref_end}"
    qry_region_id = f"qry_{qry_contig}_{qry_start}-{qry_end}"
    ref_sub["seqid"] = ref_region_id
    qry_sub["seqid"] = qry_region_id

    # Extract region sequences
    def load_fasta_index(fa):
        return {rec.id: rec for rec in SeqIO.parse(fa, "fasta")}
    ref_fai = load_fasta_index(ref_genome_fa)
    qry_fai = load_fasta_index(query_genome_fa)

    # NB: sequence always extracted from + strand of contig; feature strands remain in GFF3
    ref_seq = str(ref_fai[ref_contig].seq[ref_start-1:ref_end])
    qry_seq = str(qry_fai[qry_contig].seq[qry_start-1:qry_end])

    # Writer: GFF3 + embedded FASTA
    def write_gff3_with_fasta(df, region_id, seq, out_path):
        with open(out_path, "w") as fh:
            fh.write("##gff-version 3\n")
            fh.write(f"##sequence-region {region_id} 1 {len(seq)}\n")
            # ensure column order & types
            for _, r in df.iterrows():
                fh.write("\t".join([
                    str(r['seqid']),
                    str(r.get('source', '.')),
                    str(r['type']),
                    str(int(r['start'])),
                    str(int(r['end'])),
                    str(r.get('score', '.')),
                    str(r.get('strand', '.')),
                    str(r.get('phase', '.')),
                    str(r.get('attributes', '.'))
                ]) + "\n")
            fh.write("##FASTA\n")
            fh.write(f">{region_id}\n")
            # wrap sequence to 60 columns for readability
            for i in range(0, len(seq), 60):
                fh.write(seq[i:i+60] + "\n")

    ref_out = regions_dir / f"{ref_region_id}.gff3"
    qry_out = regions_dir / f"{qry_region_id}.gff3"
    write_gff3_with_fasta(ref_sub, ref_region_id, ref_seq, ref_out)
    write_gff3_with_fasta(qry_sub, qry_region_id, qry_seq, qry_out)

    print(f"‚úÖ Wrote GFF3+FASTA (ref):   {ref_out}")
    print(f"‚úÖ Wrote GFF3+FASTA (query): {qry_out}")

def main():
    args = parse_args()
    outdir = Path(args.outdir)
    outdir.mkdir(parents=True, exist_ok=True)

    logdir = outdir / "logs"
    logdir.mkdir(exist_ok=True)

    ref_prot_fasta = outdir / "ref_proteins.fasta"
    extracted_ref_prot = outdir / "ref_proteins_extracted.fasta"
    query_prot_fasta = outdir / "query_proteins.fasta"
    blast_output = outdir / "blastp_results.tsv"

    # Step 1: Generate full protein FASTA from reference
    run_gffread(args.ref_genome, args.ref_gtf, str(ref_prot_fasta))

    # Step 2: Extract flanking protein IDs
    ref_ids_raw = [x.strip() for x in args.ref_ids.split(",") if x.strip()]

    if args.id_type == "gene":
        # Convert gene IDs ‚Üí longest transcript IDs from ref GTF
        ref_ids = resolve_genes_to_longest_transcripts(args.ref_gtf, ref_ids_raw)
    else:
        # Use as-is (transcript IDs)
        ref_ids = ref_ids_raw

    all_ids = []
    for rid in ref_ids:
        flanks = find_flanking_genes(args.ref_gtf, rid, args.flank_method, args.window)
        all_ids.extend(flanks)
    all_ids = list(set(all_ids))

    # Step 3: Extract specific proteins
    extract_proteins(ref_prot_fasta, all_ids, extracted_ref_prot)

    # Step 4: Generate protein FASTA for query genome (same logic)
    run_gffread(args.query_genome, args.query_gtf, str(query_prot_fasta))

    # Step 5: Make BLAST DB from query protein set
    make_blast_db(query_prot_fasta, log_dir=logdir)

    # Step 6: Run blastp
    run_blastp(extracted_ref_prot, query_prot_fasta, blast_output, log_dir=logdir)

    # Step 7: Report BLAST hit order and contig congruence
    summarize_query_hits(blast_output, args.query_gtf)

    # Step 8: Create gggenomes input tracks
    generate_gggenomes_tracks(blast_output, args.query_gtf, outdir, ref_gtf=args.ref_gtf)

    # Step 9: Generate gggenomes synteny plot
    gg_seq = outdir / "gggenomes_seqs.tsv"
    gg_genes = outdir / "gggenomes_genes.tsv"
    gg_links = outdir / "gggenomes_links.tsv"
    plot_pdf = outdir / "synteny_plot.pdf"

    run_gggenomes_plot(gg_seq, gg_genes, gg_links, plot_pdf)

    # Step 10: Export regional GFF3 with embedded FASTA for Geneious
    if args.export_gff3_regions:
        export_region_gff3_with_fasta(
            blast_file=blast_output,
            ref_gtf=args.ref_gtf,
            query_gtf=args.query_gtf,
            ref_genome_fa=args.ref_genome,
            query_genome_fa=args.query_genome,
            outdir=outdir,
            padding=3000
        )

if __name__ == "__main__":
    main()
